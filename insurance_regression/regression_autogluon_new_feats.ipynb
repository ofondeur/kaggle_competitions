{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hbPR5Eviba2Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCAhAwnZlZ-_",
        "outputId": "2a1702f1-5d94-4aad-b44c-04078d47f2f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ray==2.10.0\n",
            "  Downloading ray-2.10.0-cp311-cp311-macosx_10_15_x86_64.whl (66.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/66.2 MB\u001b[0m \u001b[31m20.7 kB/s\u001b[0m eta \u001b[36m0:53:09\u001b[0mm^C\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/66.2 MB\u001b[0m \u001b[31m20.7 kB/s\u001b[0m eta \u001b[36m0:53:09\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: scikit-learn==1.4.0 in /Users/MacBook/miniconda3/lib/python3.11/site-packages (1.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /Users/MacBook/miniconda3/lib/python3.11/site-packages (from scikit-learn==1.4.0) (1.26.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/MacBook/miniconda3/lib/python3.11/site-packages (from scikit-learn==1.4.0) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/MacBook/miniconda3/lib/python3.11/site-packages (from scikit-learn==1.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/MacBook/miniconda3/lib/python3.11/site-packages (from scikit-learn==1.4.0) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ray==2.10.0\n",
        "!pip install autogluon.tabular --no-cache-dir -q\n",
        "!pip install scikit-learn==1.4.0\n",
        "!pip install autogluon.tabular[catboost]==1.2\n",
        "!pip install dask[dataframe]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On va créer des nouvelles features à partir de la date()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qEg9yybE-5sB"
      },
      "outputs": [],
      "source": [
        "def date(Df):\n",
        "    Df['Policy Start Date'] = pd.to_datetime(Df['Policy Start Date'])\n",
        "    Df['Year'] = Df['Policy Start Date'].dt.year\n",
        "    Df['Day'] = Df['Policy Start Date'].dt.day\n",
        "    Df['Month'] = Df['Policy Start Date'].dt.month\n",
        "    Df['Month_name'] = Df['Policy Start Date'].dt.month_name()\n",
        "    Df['Day_of_week'] = Df['Policy Start Date'].dt.day_name()\n",
        "    Df['Week'] = Df['Policy Start Date'].dt.isocalendar().week\n",
        "    Df['Year_sin'] = np.sin(2 * np.pi * Df['Year'])\n",
        "    Df['Year_cos'] = np.cos(2 * np.pi * Df['Year'])\n",
        "    Df['Month_sin'] = np.sin(2 * np.pi * Df['Month'] / 12)\n",
        "    Df['Month_cos'] = np.cos(2 * np.pi * Df['Month'] / 12)\n",
        "    Df['Day_sin'] = np.sin(2 * np.pi * Df['Day'] / 31)\n",
        "    Df['Day_cos'] = np.cos(2 * np.pi * Df['Day'] / 31)\n",
        "    Df['Group']=(Df['Year']-2020)*48+Df['Month']*4+Df['Day']//7\n",
        "    Df.drop('Policy Start Date', axis=1, inplace=True)\n",
        "\n",
        "    return Df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "yXnb2wZ_4Fch",
        "outputId": "9fd24af2-2e9c-4dd5-9422-974b6b11b33e"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "train=date(train)\n",
        "test=date(test)\n",
        "\n",
        "cat_cols = [col for col in train.columns if train[col].dtype == 'object']\n",
        "feature_cols = list(test.columns)\n",
        "\n",
        "#ajout des fréquences pour les colonnes d'objet (1hot encoding en fréquence)\n",
        "class CategoricalEncoder:\n",
        "    def __init__(self, train, test):\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "\n",
        "    def frequency_encode(self, cat_cols, feature_cols, drop_org=False):\n",
        "        combined = pd.concat([self.train, self.test], axis=0, ignore_index=True)\n",
        "\n",
        "        new_cat_cols = []\n",
        "        for col in cat_cols:\n",
        "            freq_encoding = combined[col].value_counts().to_dict()\n",
        "\n",
        "            self.train[f\"{col}_freq\"] = self.train[col].map(freq_encoding).astype('float')\n",
        "            self.test[f\"{col}_freq\"] = self.test[col].map(freq_encoding).astype('float')\n",
        "\n",
        "            new_col_name = f\"{col}_freq\"\n",
        "            new_cat_cols.append(new_col_name)\n",
        "            feature_cols.append(new_col_name)\n",
        "            if drop_org:\n",
        "                feature_cols.remove(col)\n",
        "\n",
        "        return self.train, self.test, new_cat_cols, feature_cols\n",
        "    \n",
        "encoder = CategoricalEncoder(train, test)\n",
        "train, test, cat_cols, feature_cols = encoder.frequency_encode(cat_cols, feature_cols, drop_org=True)\n",
        "\n",
        "train = train[feature_cols + ['Premium Amount']]\n",
        "test = test[feature_cols]\n",
        "\n",
        "\n",
        "donnee = train\n",
        "\n",
        "#on prend une fraction pour mieux tourner\n",
        "#donnee=donnee.sample(frac=0.5, random_state=42)\n",
        "donnee = donnee.drop(columns=['id'])\n",
        "\n",
        "#on passe au log1p pour coller à la métrique de test\n",
        "donnee['Premium Amount']=np.log1p(donnee['Premium Amount'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Age', 'Annual Income', 'Number of Dependents', 'Health Score',\n",
              "       'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration',\n",
              "       'Year', 'Day', 'Month', 'Week', 'Year_sin', 'Year_cos', 'Month_sin',\n",
              "       'Month_cos', 'Day_sin', 'Day_cos', 'Group', 'Gender_freq',\n",
              "       'Marital Status_freq', 'Education Level_freq', 'Occupation_freq',\n",
              "       'Location_freq', 'Policy Type_freq', 'Customer Feedback_freq',\n",
              "       'Smoking Status_freq', 'Exercise Frequency_freq', 'Property Type_freq',\n",
              "       'Month_name_freq', 'Day_of_week_freq', 'Premium Amount'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "donnee.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Pr3hIS8bxwrp",
        "outputId": "ad9e3198-e13c-4e41-b813-4b1e4d8bbaab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Annual Income</th>\n",
              "      <th>Number of Dependents</th>\n",
              "      <th>Health Score</th>\n",
              "      <th>Previous Claims</th>\n",
              "      <th>Vehicle Age</th>\n",
              "      <th>Credit Score</th>\n",
              "      <th>Insurance Duration</th>\n",
              "      <th>Year</th>\n",
              "      <th>Day</th>\n",
              "      <th>...</th>\n",
              "      <th>Occupation_freq</th>\n",
              "      <th>Location_freq</th>\n",
              "      <th>Policy Type_freq</th>\n",
              "      <th>Customer Feedback_freq</th>\n",
              "      <th>Smoking Status_freq</th>\n",
              "      <th>Exercise Frequency_freq</th>\n",
              "      <th>Property Type_freq</th>\n",
              "      <th>Month_name_freq</th>\n",
              "      <th>Day_of_week_freq</th>\n",
              "      <th>Premium Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>10049.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.598761</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2023</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>470636.0</td>\n",
              "      <td>663201.0</td>\n",
              "      <td>669475.0</td>\n",
              "      <td>625952.0</td>\n",
              "      <td>996268.0</td>\n",
              "      <td>510693.0</td>\n",
              "      <td>667500.0</td>\n",
              "      <td>162307.0</td>\n",
              "      <td>284861.0</td>\n",
              "      <td>7.962067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.0</td>\n",
              "      <td>31678.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.569731</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>694.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2023</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>668067.0</td>\n",
              "      <td>665822.0</td>\n",
              "      <td>629122.0</td>\n",
              "      <td>1003732.0</td>\n",
              "      <td>498230.0</td>\n",
              "      <td>667500.0</td>\n",
              "      <td>164442.0</td>\n",
              "      <td>287191.0</td>\n",
              "      <td>7.302496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.0</td>\n",
              "      <td>25602.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>47.177549</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2023</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>470636.0</td>\n",
              "      <td>668732.0</td>\n",
              "      <td>669475.0</td>\n",
              "      <td>614826.0</td>\n",
              "      <td>1003732.0</td>\n",
              "      <td>510693.0</td>\n",
              "      <td>667500.0</td>\n",
              "      <td>165556.0</td>\n",
              "      <td>284861.0</td>\n",
              "      <td>6.342121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.0</td>\n",
              "      <td>141855.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.938144</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2024</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>668067.0</td>\n",
              "      <td>664703.0</td>\n",
              "      <td>625952.0</td>\n",
              "      <td>1003732.0</td>\n",
              "      <td>491143.0</td>\n",
              "      <td>666022.0</td>\n",
              "      <td>164442.0</td>\n",
              "      <td>287424.0</td>\n",
              "      <td>6.641182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.0</td>\n",
              "      <td>39651.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.376094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>470636.0</td>\n",
              "      <td>668067.0</td>\n",
              "      <td>669475.0</td>\n",
              "      <td>625952.0</td>\n",
              "      <td>1003732.0</td>\n",
              "      <td>510693.0</td>\n",
              "      <td>667500.0</td>\n",
              "      <td>162307.0</td>\n",
              "      <td>287424.0</td>\n",
              "      <td>7.612337</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  Annual Income  Number of Dependents  Health Score  Previous Claims  \\\n",
              "0  19.0        10049.0                   1.0     22.598761              2.0   \n",
              "1  39.0        31678.0                   3.0     15.569731              1.0   \n",
              "2  23.0        25602.0                   3.0     47.177549              1.0   \n",
              "3  21.0       141855.0                   2.0     10.938144              1.0   \n",
              "4  21.0        39651.0                   1.0     20.376094              0.0   \n",
              "\n",
              "   Vehicle Age  Credit Score  Insurance Duration  Year  Day  ...  \\\n",
              "0         17.0         372.0                 5.0  2023   23  ...   \n",
              "1         12.0         694.0                 2.0  2023   12  ...   \n",
              "2         14.0           NaN                 3.0  2023   30  ...   \n",
              "3          0.0         367.0                 1.0  2024   12  ...   \n",
              "4          8.0         598.0                 4.0  2021    1  ...   \n",
              "\n",
              "   Occupation_freq  Location_freq  Policy Type_freq  Customer Feedback_freq  \\\n",
              "0         470636.0       663201.0          669475.0                625952.0   \n",
              "1              NaN       668067.0          665822.0                629122.0   \n",
              "2         470636.0       668732.0          669475.0                614826.0   \n",
              "3              NaN       668067.0          664703.0                625952.0   \n",
              "4         470636.0       668067.0          669475.0                625952.0   \n",
              "\n",
              "   Smoking Status_freq  Exercise Frequency_freq  Property Type_freq  \\\n",
              "0             996268.0                 510693.0            667500.0   \n",
              "1            1003732.0                 498230.0            667500.0   \n",
              "2            1003732.0                 510693.0            667500.0   \n",
              "3            1003732.0                 491143.0            666022.0   \n",
              "4            1003732.0                 510693.0            667500.0   \n",
              "\n",
              "   Month_name_freq  Day_of_week_freq  Premium Amount  \n",
              "0         162307.0          284861.0        7.962067  \n",
              "1         164442.0          287191.0        7.302496  \n",
              "2         165556.0          284861.0        6.342121  \n",
              "3         164442.0          287424.0        6.641182  \n",
              "4         162307.0          287424.0        7.612337  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "donnee.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bh7fvrdNm2FH"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
          ]
        }
      ],
      "source": [
        "import catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W05ZUumw7ti6"
      },
      "outputs": [],
      "source": [
        "#pour vérifier qu'on s'entraine pas sur des NaN \n",
        "donnee = donnee.dropna(subset=['Premium Amount'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8EMLXOlyYRS",
        "outputId": "1a691946-976d-425b-daa3-f9d816765330"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1200000, 32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "donnee.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U6PGvzeJ4aom",
        "outputId": "173c37e1-9291-46ac-9db8-08f6d09a3807"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/kag/auto\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.73 GB / 12.67 GB (76.8%)\n",
            "Disk Space Avail:   74.02 GB / 107.72 GB (68.7%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=4, num_bag_folds=7, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 6250s of the 25000s of remaining time (25%).\n",
            "\t\tContext path: \"/kag/auto/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Beginning AutoGluon training ... Time limit = 6250s\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m AutoGluon will save models to \"/kag/auto/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Train Data Rows:    1066666\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Train Data Columns: 19\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Label Column:       Premium Amount\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Problem Type:       regression\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tAvailable Memory:                    9907.87 MB\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTrain Data (Original)  Memory Usage: 705.44 MB (7.1% of available memory)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Data size prior to feature transformation consumes 7.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\t('float', [])  :  9 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\t('object', []) : 10 | ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', ...]\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\t('category', [])  : 8 | ['Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', ...]\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\t('float', [])     : 9 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t\t('int', ['bool']) : 2 | ['Gender', 'Smoking Status']\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t7.7s = Fit runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t19 features in original data used to generate 19 features in processed data.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTrain Data (Processed) Memory Usage: 83.42 MB (0.8% of available memory)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Data preprocessing and feature engineering runtime = 8.3s ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m AutoGluon will fit 5 stack levels (L1 to L5) ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1664.03s of the 6241.63s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.184\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t7.14s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t22.85s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1628.50s of the 6206.10s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.2152\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t7.64s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t25.74s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1594.03s of the 6171.63s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=6.63%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=11573)\u001b[0m [1000]\tvalid_set's rmse: 1.05411\n",
            "\u001b[36m(_ray_fit pid=11572)\u001b[0m [2000]\tvalid_set's rmse: 1.04721\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=11572)\u001b[0m \tRan out of time, early stopping on iteration 2293. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=11572)\u001b[0m \t[1899]\tvalid_set's rmse: 1.0472\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=13137)\u001b[0m [1000]\tvalid_set's rmse: 1.04512\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13108)\u001b[0m [2000]\tvalid_set's rmse: 1.0493\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=13137)\u001b[0m \tRan out of time, early stopping on iteration 2216. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13137)\u001b[0m \t[2216]\tvalid_set's rmse: 1.04464\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=14687)\u001b[0m [1000]\tvalid_set's rmse: 1.0488\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14658)\u001b[0m [2000]\tvalid_set's rmse: 1.05127\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=14658)\u001b[0m \tRan out of time, early stopping on iteration 2220. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14658)\u001b[0m \t[2152]\tvalid_set's rmse: 1.05121\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=16221)\u001b[0m [1000]\tvalid_set's rmse: 1.05079\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16221)\u001b[0m [2000]\tvalid_set's rmse: 1.05041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0492\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t1334.72s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t328.26s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 226.66s of the 4804.26s of remaining time.\n",
            "\u001b[36m(_ray_fit pid=14687)\u001b[0m \tRan out of time, early stopping on iteration 2212. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=14687)\u001b[0m \t[2087]\tvalid_set's rmse: 1.04812\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=6.75%)\n",
            "\u001b[36m(_ray_fit pid=17362)\u001b[0m \tRan out of time, early stopping on iteration 250. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=17362)\u001b[0m \t[215]\tvalid_set's rmse: 1.04983\n",
            "\u001b[36m(_ray_fit pid=17633)\u001b[0m \tRan out of time, early stopping on iteration 254. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17633)\u001b[0m \t[252]\tvalid_set's rmse: 1.04587\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17919)\u001b[0m \tRan out of time, early stopping on iteration 215. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17919)\u001b[0m \t[215]\tvalid_set's rmse: 1.04759\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=18189)\u001b[0m \tRan out of time, early stopping on iteration 498. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=18189)\u001b[0m \t[492]\tvalid_set's rmse: 1.0472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0456\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t212.73s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t31.7s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 4.30s of the 4581.90s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 3867.3s to train, which exceeds the maximum time limit of 3.5s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 4528.86s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0456\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.9s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1508.91s of the 4527.72s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.17%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0461\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t345.48s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t31.62s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 1154.48s of the 4173.30s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.19%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0454\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t159.12s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t10.44s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 988.22s of the 4007.03s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 8100.0s to train, which exceeds the maximum time limit of 986.8s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 878.51s of the 3897.32s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.25%)\n",
            "\u001b[36m(_ray_fit pid=22067)\u001b[0m \tRan out of time, early stopping on iteration 44.\n",
            "\u001b[36m(_ray_fit pid=22807)\u001b[0m \tRan out of time, early stopping on iteration 45.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=23551)\u001b[0m \tRan out of time, early stopping on iteration 45.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=24306)\u001b[0m \tRan out of time, early stopping on iteration 76.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0463\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t693.44s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.79s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 180.69s of the 3199.51s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 1354.6s to train, which exceeds the maximum time limit of 179.4s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L2.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 161.05s of the 3179.86s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tMemory not enough to fit 7 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.35% memory usage per fold, 57.40%/80.00% total).\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=14.35%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 136.71s of the 3155.53s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tMemory not enough to fit 7 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.74% memory usage per fold, 46.95%/80.00% total).\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=11.74%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0646\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t127.88s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t13.89s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 3016.86s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.875, 'LightGBMXT_BAG_L2': 0.125}\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0454\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t1.67s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.08s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting 106 L3 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 1339.67s of the 3014.82s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.47%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0458\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t187.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t10.54s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBM_BAG_L3 ... Training model for up to 1145.08s of the 2820.24s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.49%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0454\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t140.59s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t7.64s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: RandomForestMSE_BAG_L3 ... Training model for up to 996.52s of the 2671.67s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 7628.2s to train, which exceeds the maximum time limit of 995.4s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping RandomForestMSE_BAG_L3.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: CatBoost_BAG_L3 ... Training model for up to 893.33s of the 2568.48s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.61%)\n",
            "\u001b[36m(_ray_fit pid=29103)\u001b[0m \tRan out of time, early stopping on iteration 43.\n",
            "\u001b[36m(_ray_fit pid=29855)\u001b[0m \tRan out of time, early stopping on iteration 43.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=30619)\u001b[0m \tRan out of time, early stopping on iteration 43.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=31378)\u001b[0m \tRan out of time, early stopping on iteration 75.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0461\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t703.52s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.84s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L3 ... Training model for up to 185.57s of the 1860.72s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 42 due to low time. Expected time usage reduced from 1280.0s -> 183.5s...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 58.68s compared to 50.74s of available time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L3.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 1670.27s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L3': 0.75, 'LightGBMXT_BAG_L3': 0.188, 'CatBoost_BAG_L3': 0.062}\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0454\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.68s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting 106 L4 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 1112.71s of the 1669.39s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.26%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0459\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t236.88s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t21.44s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBM_BAG_L4 ... Training model for up to 869.40s of the 1426.08s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.26%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0455\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t136.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t7.2s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: RandomForestMSE_BAG_L4 ... Training model for up to 725.34s of the 1282.02s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 6391.7s to train, which exceeds the maximum time limit of 724.3s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping RandomForestMSE_BAG_L4.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: CatBoost_BAG_L4 ... Training model for up to 638.74s of the 1195.41s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.20%)\n",
            "\u001b[36m(_ray_fit pid=35687)\u001b[0m \tRan out of time, early stopping on iteration 29.\n",
            "\u001b[36m(_ray_fit pid=36238)\u001b[0m \tRan out of time, early stopping on iteration 30.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=36798)\u001b[0m \tRan out of time, early stopping on iteration 31.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=37354)\u001b[0m \tRan out of time, early stopping on iteration 50.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0478\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t497.25s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.76s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L4 ... Training model for up to 135.83s of the 692.51s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 1236.0s to train, which exceeds the maximum time limit of 134.8s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L4.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 117.94s of the 674.62s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tMemory not enough to fit 7 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.18% memory usage per fold, 56.70%/80.00% total).\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=14.18%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L4.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: XGBoost_BAG_L4 ... Training model for up to 99.02s of the 655.70s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=10.77%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0816\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t107.23s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t9.46s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.00s of the 543.05s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L4': 0.8, 'LightGBMXT_BAG_L4': 0.2}\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0455\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t1.23s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting 106 L5 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBMXT_BAG_L5 ... Training model for up to 541.67s of the 541.50s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.54%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0459\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t213.44s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t14.26s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: LightGBM_BAG_L5 ... Training model for up to 320.77s of the 320.59s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.53%)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0455\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t132.57s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t6.86s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: RandomForestMSE_BAG_L5 ... Training model for up to 181.34s of the 181.17s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 7115.0s to train, which exceeds the maximum time limit of 179.9s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping RandomForestMSE_BAG_L5.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: CatBoost_BAG_L5 ... Training model for up to 84.61s of the 84.44s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.60%)\n",
            "\u001b[36m(_ray_fit pid=41859)\u001b[0m \tRan out of time, early stopping on iteration 1.\n",
            "\u001b[36m(_ray_fit pid=41974)\u001b[0m \tRan out of time, early stopping on iteration 1.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=42095)\u001b[0m \tRan out of time, early stopping on iteration 1.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=42204)\u001b[0m \tRan out of time, early stopping on iteration 4.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0895\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t55.11s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.54s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L5 ... Training model for up to 25.15s of the 24.98s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tWarning: Model is expected to require 1079.7s to train, which exceeds the maximum time limit of 23.4s, skipping model...\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L5.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Fitting model: WeightedEnsemble_L6 ... Training model for up to 360.00s of the 8.11s of remaining time.\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.429, 'LightGBM_BAG_L5': 0.286, 'LightGBM_BAG_L1': 0.143, 'LightGBM_BAG_L3': 0.143}\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t-1.0453\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t3.23s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m AutoGluon training complete, total runtime = 6245.61s ... Best model: WeightedEnsemble_L6 | Estimated inference throughput: 312.0 rows/s (152381 batch size)\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kag/auto/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=10992)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                    model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0         LightGBM_BAG_L3      -1.045468  -1.045431  root_mean_squared_error      220.178257     472.931644  3028.725482                 4.432693                7.643802         140.587976            3       True         12\n",
            "1     WeightedEnsemble_L4      -1.045470  -1.045412  root_mean_squared_error      227.281944     484.354975  3920.317498                 0.006440                0.043707           0.681324            4       True         14\n",
            "2         LightGBM_BAG_L4      -1.045474  -1.045482  root_mean_squared_error      231.572012     491.509538  4056.024558                 4.296508                7.198269         136.388384            4       True         16\n",
            "3     WeightedEnsemble_L6      -1.045481  -1.045299  root_mean_squared_error      254.398643     530.064311  5033.187799                 0.005970                0.039551           3.233929            6       True         23\n",
            "4     WeightedEnsemble_L5      -1.045483  -1.045466  root_mean_squared_error      242.311750     513.019234  4294.134749                 0.005084                0.070436           1.232439            5       True         19\n",
            "5         LightGBM_BAG_L5      -1.045486  -1.045481  root_mean_squared_error      254.392673     530.024760  5029.953870                 4.834795                6.858727         132.566561            5       True         21\n",
            "6         LightGBM_BAG_L2      -1.045534  -1.045383  root_mean_squared_error      190.908450     418.984705  1721.337913                 5.185193               10.438883         159.115618            2       True          7\n",
            "7     WeightedEnsemble_L3      -1.045541  -1.045373  root_mean_squared_error      209.036750     450.680561  2068.490721                 0.003761                0.075078           1.669732            3       True         10\n",
            "8       LightGBMXT_BAG_L3      -1.045651  -1.045757  root_mean_squared_error      222.117694     475.824636  3075.530433                 6.372130               10.536794         187.392927            3       True         11\n",
            "9       LightGBMXT_BAG_L5      -1.045742  -1.045859  root_mean_squared_error      259.046634     537.429189  5110.826791                 9.488757               14.263155         213.439481            5       True         20\n",
            "10      LightGBMXT_BAG_L4      -1.045837  -1.045920  root_mean_squared_error      238.010158     505.750529  4156.513926                10.734654               21.439260         236.877752            4       True         15\n",
            "11        LightGBM_BAG_L1      -1.045849  -1.045612  root_mean_squared_error       17.862249      31.697344   212.727964                17.862249               31.697344         212.727964            1       True          4\n",
            "12    WeightedEnsemble_L2      -1.045849  -1.045612  root_mean_squared_error       17.866526      31.737791   213.630149                 0.004277                0.040447           0.902185            2       True          5\n",
            "13      LightGBMXT_BAG_L2      -1.046069  -1.046073  root_mean_squared_error      203.847796     440.166600  1907.705371                18.124540               31.620778         345.483077            2       True          6\n",
            "14        CatBoost_BAG_L3      -1.046189  -1.046146  root_mean_squared_error      216.470681     466.130673  3591.655272                 0.725118                0.842831         703.517766            3       True         13\n",
            "15        CatBoost_BAG_L2      -1.046357  -1.046256  root_mean_squared_error      187.140224     409.334470  2255.662105                 1.416967                0.788648         693.439811            2       True          8\n",
            "16        CatBoost_BAG_L4      -1.047830  -1.047810  root_mean_squared_error      227.842983     485.068375  4416.886648                 0.567478                0.757107         497.250474            4       True         17\n",
            "17      LightGBMXT_BAG_L1      -1.049044  -1.049210  root_mean_squared_error      160.327685     328.255846  1334.717361               160.327685              328.255846        1334.717361            1       True          3\n",
            "18         XGBoost_BAG_L2      -1.063642  -1.064645  root_mean_squared_error      191.018864     422.439534  1690.099001                 5.295607               13.893712         127.876706            2       True          9\n",
            "19         XGBoost_BAG_L4      -1.080533  -1.081621  root_mean_squared_error      233.959238     493.771397  4026.870700                 6.683733                9.460129         107.234525            4       True         18\n",
            "20        CatBoost_BAG_L5      -1.089806  -1.089452  root_mean_squared_error      249.779758     523.709904  4952.496503                 0.221881                0.543871          55.109194            5       True         22\n",
            "21  KNeighborsUnif_BAG_L1      -1.184601  -1.183987  root_mean_squared_error        3.867521      22.854465     7.140438                 3.867521               22.854465           7.140438            1       True          1\n",
            "22  KNeighborsDist_BAG_L1      -1.217271  -1.215227  root_mean_squared_error        3.665802      25.738167     7.636532                 3.665802               25.738167           7.636532            1       True          2\n",
            "\t4\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t6517s\t = DyStack   runtime |\t18483s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=4.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=4)`\n",
            "Beginning AutoGluon training ... Time limit = 18483s\n",
            "AutoGluon will save models to \"/kag/auto\"\n",
            "Train Data Rows:    1200000\n",
            "Train Data Columns: 19\n",
            "Label Column:       Premium Amount\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10078.06 MB\n",
            "\tTrain Data (Original)  Memory Usage: 793.67 MB (7.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 7.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  :  9 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
            "\t\t('object', []) : 10 | ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 8 | ['Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', ...]\n",
            "\t\t('float', [])     : 9 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Gender', 'Smoking Status']\n",
            "\t8.4s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 93.85 MB (0.9% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 9.38s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 5 stack levels (L1 to L5) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 4924.96s of the 18473.21s of remaining time.\n",
            "\t-1.184\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.33s\t = Training   runtime\n",
            "\t29.82s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 4882.00s of the 18430.25s of remaining time.\n",
            "\t-1.2142\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.4s\t = Training   runtime\n",
            "\t26.34s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4845.35s of the 18393.60s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=6.74%)\n",
            "\t-1.049\t = Validation score   (-root_mean_squared_error)\n",
            "\t2168.54s\t = Training   runtime\n",
            "\t448.04s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2623.10s of the 16171.34s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=6.72%)\n",
            "\t-1.0455\t = Validation score   (-root_mean_squared_error)\n",
            "\t341.73s\t = Training   runtime\n",
            "\t36.84s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 2272.82s of the 15821.06s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 174 due to low time. Expected time usage reduced from 3913.3s -> 2271.9s...\n",
            "\t-1.0482\t = Validation score   (-root_mean_squared_error)\n",
            "\t2313.83s\t = Training   runtime\n",
            "\t31.89s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 492.50s of the 13472.77s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.714, 'RandomForestMSE_BAG_L1': 0.286}\n",
            "\t-1.0451\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.12s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4489.37s of the 13471.35s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.63%)\n",
            "\t-1.0449\t = Validation score   (-root_mean_squared_error)\n",
            "\t342.02s\t = Training   runtime\n",
            "\t27.66s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4137.52s of the 13119.49s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.94%)\n",
            "\t-1.0445\t = Validation score   (-root_mean_squared_error)\n",
            "\t184.38s\t = Training   runtime\n",
            "\t12.12s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 3943.63s of the 12925.60s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 130 due to low time. Expected time usage reduced from 9034.2s -> 3941.9s...\n",
            "\t-1.0483\t = Validation score   (-root_mean_squared_error)\n",
            "\t4232.53s\t = Training   runtime\n",
            "\t24.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 448.94s of the 8666.38s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.727, 'LightGBMXT_BAG_L2': 0.182, 'RandomForestMSE_BAG_L2': 0.091}\n",
            "\t-1.0445\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting 106 L3 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 3850.38s of the 8665.34s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=9.08%)\n",
            "\t-1.0449\t = Validation score   (-root_mean_squared_error)\n",
            "\t276.28s\t = Training   runtime\n",
            "\t23.52s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L3 ... Training model for up to 3555.50s of the 8370.46s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.08%)\n",
            "\t-1.0445\t = Validation score   (-root_mean_squared_error)\n",
            "\t151.46s\t = Training   runtime\n",
            "\t9.48s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L3 ... Training model for up to 3398.93s of the 8213.89s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 124 due to low time. Expected time usage reduced from 8170.1s -> 3397.7s...\n",
            "\t-1.0486\t = Validation score   (-root_mean_squared_error)\n",
            "\t3445.02s\t = Training   runtime\n",
            "\t25.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L4 ... Training model for up to 385.04s of the 4740.29s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L3': 0.722, 'LightGBMXT_BAG_L3': 0.222, 'RandomForestMSE_BAG_L3': 0.056}\n",
            "\t-1.0445\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting 106 L4 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 3158.45s of the 4738.53s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.19%)\n",
            "\t-1.0449\t = Validation score   (-root_mean_squared_error)\n",
            "\t278.58s\t = Training   runtime\n",
            "\t24.57s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L4 ... Training model for up to 2869.28s of the 4449.35s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.18%)\n",
            "\t-1.0445\t = Validation score   (-root_mean_squared_error)\n",
            "\t145.39s\t = Training   runtime\n",
            "\t7.15s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L4 ... Training model for up to 2718.06s of the 4298.13s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 100 due to low time. Expected time usage reduced from 8078.8s -> 2716.5s...\n",
            "\t-1.0493\t = Validation score   (-root_mean_squared_error)\n",
            "\t2726.17s\t = Training   runtime\n",
            "\t19.68s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.00s of the 1549.72s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L4': 0.773, 'LightGBMXT_BAG_L4': 0.182, 'RandomForestMSE_BAG_L4': 0.045}\n",
            "\t-1.0445\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting 106 L5 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L5 ... Training model for up to 1548.77s of the 1548.64s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.36%)\n",
            "\t-1.045\t = Validation score   (-root_mean_squared_error)\n",
            "\t275.81s\t = Training   runtime\n",
            "\t27.16s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L5 ... Training model for up to 1265.71s of the 1265.59s of remaining time.\n",
            "\tFitting 7 child models (S1F1 - S1F7) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=8.35%)\n",
            "\t-1.0446\t = Validation score   (-root_mean_squared_error)\n",
            "\t143.94s\t = Training   runtime\n",
            "\t8.34s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L5 ... Training model for up to 1116.53s of the 1116.41s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 43 due to low time. Expected time usage reduced from 7754.6s -> 1115.3s...\n",
            "\t-1.0542\t = Validation score   (-root_mean_squared_error)\n",
            "\t1168.59s\t = Training   runtime\n",
            "\t11.93s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L6 ... Training model for up to 360.00s of the -65.90s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.391, 'LightGBM_BAG_L4': 0.261, 'LightGBM_BAG_L5': 0.174, 'LightGBMXT_BAG_L2': 0.043, 'RandomForestMSE_BAG_L2': 0.043, 'LightGBM_BAG_L3': 0.043, 'RandomForestMSE_BAG_L5': 0.043}\n",
            "\t-1.0444\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.26s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 18552.25s ... Best model: WeightedEnsemble_L6 | Estimated inference throughput: 275.7 rows/s (171429 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kag/auto\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"WeightedEnsemble_L6\",\n          \"LightGBM_BAG_L1\",\n          \"LightGBMXT_BAG_L3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04529871387498849,\n        \"min\": -1.2142277378962736,\n        \"max\": -1.0443935339286816,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          -1.0443935339286816,\n          -1.0455202674712039,\n          -1.0448707310142513\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"root_mean_squared_error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 282.64349342965346,\n        \"min\": 26.339141845703125,\n        \"max\": 773.4166960716248,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          766.579922914505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6405.181876656227,\n        \"min\": 9.33051085472107,\n        \"max\": 17940.447446346283,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          17940.447446346283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92.78725537076792,\n        \"min\": 0.046202898025512695,\n        \"max\": 448.0431818962097,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.06037425994873047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1274.4677156252628,\n        \"min\": 0.7191145420074463,\n        \"max\": 4232.529144287109,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.264580488204956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 22,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1b97dbd9-c6bd-41e8-8c13-063d4577b3a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L6</td>\n",
              "      <td>-1.044394</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>766.579923</td>\n",
              "      <td>17940.447446</td>\n",
              "      <td>0.060374</td>\n",
              "      <td>3.264580</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>-1.044482</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>636.789352</td>\n",
              "      <td>9602.466743</td>\n",
              "      <td>0.046203</td>\n",
              "      <td>0.719115</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WeightedEnsemble_L4</td>\n",
              "      <td>-1.044508</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>694.938521</td>\n",
              "      <td>13475.682417</td>\n",
              "      <td>0.090362</td>\n",
              "      <td>1.169780</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WeightedEnsemble_L5</td>\n",
              "      <td>-1.044515</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>746.314260</td>\n",
              "      <td>16625.450210</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>0.792369</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBM_BAG_L4</td>\n",
              "      <td>-1.044535</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>701.999199</td>\n",
              "      <td>13619.903363</td>\n",
              "      <td>7.151040</td>\n",
              "      <td>145.390726</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>-1.044539</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>585.042207</td>\n",
              "      <td>5027.198957</td>\n",
              "      <td>12.117283</td>\n",
              "      <td>184.379580</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBM_BAG_L3</td>\n",
              "      <td>-1.044546</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>646.222691</td>\n",
              "      <td>9753.210321</td>\n",
              "      <td>9.479542</td>\n",
              "      <td>151.462693</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LightGBM_BAG_L5</td>\n",
              "      <td>-1.044609</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>754.593929</td>\n",
              "      <td>16768.596400</td>\n",
              "      <td>8.341230</td>\n",
              "      <td>143.938559</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LightGBMXT_BAG_L3</td>\n",
              "      <td>-1.044871</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>660.259337</td>\n",
              "      <td>9878.026357</td>\n",
              "      <td>23.516188</td>\n",
              "      <td>276.278728</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>-1.044920</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>600.581443</td>\n",
              "      <td>5184.838905</td>\n",
              "      <td>27.656520</td>\n",
              "      <td>342.019527</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LightGBMXT_BAG_L4</td>\n",
              "      <td>-1.044945</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>719.421649</td>\n",
              "      <td>13753.094472</td>\n",
              "      <td>24.573490</td>\n",
              "      <td>278.581835</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LightGBMXT_BAG_L5</td>\n",
              "      <td>-1.045029</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>773.416696</td>\n",
              "      <td>16900.470890</td>\n",
              "      <td>27.163997</td>\n",
              "      <td>275.813050</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>-1.045060</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>68.769237</td>\n",
              "      <td>2656.676371</td>\n",
              "      <td>0.048846</td>\n",
              "      <td>1.122553</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>-1.045520</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>36.835097</td>\n",
              "      <td>341.725870</td>\n",
              "      <td>36.835097</td>\n",
              "      <td>341.725870</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RandomForestMSE_BAG_L1</td>\n",
              "      <td>-1.048245</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>31.885294</td>\n",
              "      <td>2313.827948</td>\n",
              "      <td>31.885294</td>\n",
              "      <td>2313.827948</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RandomForestMSE_BAG_L2</td>\n",
              "      <td>-1.048291</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>596.969347</td>\n",
              "      <td>9075.348522</td>\n",
              "      <td>24.044423</td>\n",
              "      <td>4232.529144</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RandomForestMSE_BAG_L3</td>\n",
              "      <td>-1.048557</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>661.852430</td>\n",
              "      <td>13046.771216</td>\n",
              "      <td>25.109280</td>\n",
              "      <td>3445.023587</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>-1.048956</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>448.043182</td>\n",
              "      <td>2168.537903</td>\n",
              "      <td>448.043182</td>\n",
              "      <td>2168.537903</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>RandomForestMSE_BAG_L4</td>\n",
              "      <td>-1.049258</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>714.528169</td>\n",
              "      <td>16200.685279</td>\n",
              "      <td>19.680010</td>\n",
              "      <td>2726.172642</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>RandomForestMSE_BAG_L5</td>\n",
              "      <td>-1.054173</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>758.178318</td>\n",
              "      <td>17793.244307</td>\n",
              "      <td>11.925619</td>\n",
              "      <td>1168.586466</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>KNeighborsUnif_BAG_L1</td>\n",
              "      <td>-1.183975</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>29.822208</td>\n",
              "      <td>9.330511</td>\n",
              "      <td>29.822208</td>\n",
              "      <td>9.330511</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>KNeighborsDist_BAG_L1</td>\n",
              "      <td>-1.214228</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>26.339142</td>\n",
              "      <td>9.397146</td>\n",
              "      <td>26.339142</td>\n",
              "      <td>9.397146</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b97dbd9-c6bd-41e8-8c13-063d4577b3a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b97dbd9-c6bd-41e8-8c13-063d4577b3a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b97dbd9-c6bd-41e8-8c13-063d4577b3a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a02b462f-ee56-4351-aa1f-9e2efb12c249\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a02b462f-ee56-4351-aa1f-9e2efb12c249')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a02b462f-ee56-4351-aa1f-9e2efb12c249 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     model  score_val              eval_metric  pred_time_val  \\\n",
              "0      WeightedEnsemble_L6  -1.044394  root_mean_squared_error     766.579923   \n",
              "1      WeightedEnsemble_L3  -1.044482  root_mean_squared_error     636.789352   \n",
              "2      WeightedEnsemble_L4  -1.044508  root_mean_squared_error     694.938521   \n",
              "3      WeightedEnsemble_L5  -1.044515  root_mean_squared_error     746.314260   \n",
              "4          LightGBM_BAG_L4  -1.044535  root_mean_squared_error     701.999199   \n",
              "5          LightGBM_BAG_L2  -1.044539  root_mean_squared_error     585.042207   \n",
              "6          LightGBM_BAG_L3  -1.044546  root_mean_squared_error     646.222691   \n",
              "7          LightGBM_BAG_L5  -1.044609  root_mean_squared_error     754.593929   \n",
              "8        LightGBMXT_BAG_L3  -1.044871  root_mean_squared_error     660.259337   \n",
              "9        LightGBMXT_BAG_L2  -1.044920  root_mean_squared_error     600.581443   \n",
              "10       LightGBMXT_BAG_L4  -1.044945  root_mean_squared_error     719.421649   \n",
              "11       LightGBMXT_BAG_L5  -1.045029  root_mean_squared_error     773.416696   \n",
              "12     WeightedEnsemble_L2  -1.045060  root_mean_squared_error      68.769237   \n",
              "13         LightGBM_BAG_L1  -1.045520  root_mean_squared_error      36.835097   \n",
              "14  RandomForestMSE_BAG_L1  -1.048245  root_mean_squared_error      31.885294   \n",
              "15  RandomForestMSE_BAG_L2  -1.048291  root_mean_squared_error     596.969347   \n",
              "16  RandomForestMSE_BAG_L3  -1.048557  root_mean_squared_error     661.852430   \n",
              "17       LightGBMXT_BAG_L1  -1.048956  root_mean_squared_error     448.043182   \n",
              "18  RandomForestMSE_BAG_L4  -1.049258  root_mean_squared_error     714.528169   \n",
              "19  RandomForestMSE_BAG_L5  -1.054173  root_mean_squared_error     758.178318   \n",
              "20   KNeighborsUnif_BAG_L1  -1.183975  root_mean_squared_error      29.822208   \n",
              "21   KNeighborsDist_BAG_L1  -1.214228  root_mean_squared_error      26.339142   \n",
              "\n",
              "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              "0   17940.447446                0.060374           3.264580            6   \n",
              "1    9602.466743                0.046203           0.719115            3   \n",
              "2   13475.682417                0.090362           1.169780            4   \n",
              "3   16625.450210                0.061561           0.792369            5   \n",
              "4   13619.903363                7.151040         145.390726            4   \n",
              "5    5027.198957               12.117283         184.379580            2   \n",
              "6    9753.210321                9.479542         151.462693            3   \n",
              "7   16768.596400                8.341230         143.938559            5   \n",
              "8    9878.026357               23.516188         276.278728            3   \n",
              "9    5184.838905               27.656520         342.019527            2   \n",
              "10  13753.094472               24.573490         278.581835            4   \n",
              "11  16900.470890               27.163997         275.813050            5   \n",
              "12   2656.676371                0.048846           1.122553            2   \n",
              "13    341.725870               36.835097         341.725870            1   \n",
              "14   2313.827948               31.885294        2313.827948            1   \n",
              "15   9075.348522               24.044423        4232.529144            2   \n",
              "16  13046.771216               25.109280        3445.023587            3   \n",
              "17   2168.537903              448.043182        2168.537903            1   \n",
              "18  16200.685279               19.680010        2726.172642            4   \n",
              "19  17793.244307               11.925619        1168.586466            5   \n",
              "20      9.330511               29.822208           9.330511            1   \n",
              "21      9.397146               26.339142           9.397146            1   \n",
              "\n",
              "    can_infer  fit_order  \n",
              "0        True         22  \n",
              "1        True         10  \n",
              "2        True         14  \n",
              "3        True         18  \n",
              "4        True         16  \n",
              "5        True          8  \n",
              "6        True         12  \n",
              "7        True         20  \n",
              "8        True         11  \n",
              "9        True          7  \n",
              "10       True         15  \n",
              "11       True         19  \n",
              "12       True          6  \n",
              "13       True          4  \n",
              "14       True          5  \n",
              "15       True          9  \n",
              "16       True         13  \n",
              "17       True          3  \n",
              "18       True         17  \n",
              "19       True         21  \n",
              "20       True          1  \n",
              "21       True          2  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "import time\n",
        "\n",
        "predictor = TabularPredictor(path='/kag/auto',label='Premium Amount',\n",
        "                              problem_type = 'regression',\n",
        "                              eval_metric = 'root_mean_squared_error',\n",
        "                              )\n",
        "\n",
        "#TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kag/auto/ds_sub_fit/sub_fit_ho\")\n",
        "predictor.fit(train_data= donnee,\n",
        "                       presets='best_quality',\n",
        "                       time_limit = 25000,\n",
        "                       #modifier la time_limit pour les tests\n",
        "                       num_bag_folds = 7,\n",
        "                       num_stack_levels = 4,\n",
        "                       auto_stack = True,\n",
        "                       dynamic_stacking=True\n",
        "                       )\n",
        "predictor.leaderboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTta46E-GyrP",
        "outputId": "a67c9a42-be46-4347-8821-3eb7b8b76596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n"
          ]
        }
      ],
      "source": [
        "X=test.drop(columns=['id'])\n",
        "batch_size = 10000\n",
        "predictions = []\n",
        "c=0\n",
        "predictor = TabularPredictor.load(\"/kag/auto\")\n",
        "#utilise une boucle pour le .predict pour voir l'avancé\n",
        "for i in range(0, len(X), batch_size):\n",
        "    batch = X.iloc[i:i + batch_size]\n",
        "    predictions.append(predictor.predict(batch,model='WeightedEnsemble_L6'))#modifier avec lemeilleur model de test d'autogluon\n",
        "    print(c)\n",
        "    c+=1\n",
        "y_pred_test = pd.concat(predictions, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yuyaq0L6JK41"
      },
      "outputs": [],
      "source": [
        "test['Premium Amount']=np.expm1(y_pred_test)\n",
        "test1=test[['id','Premium Amount']]\n",
        "test1.to_csv('submission_autog_25ksec.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
